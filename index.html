<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <title>PAST-SSM</title>
    <meta name="author" content="Jiazhou Zhou">
    <meta name="description" content="Project page of PASS">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="icon" type="image/png" href="eccv_logo.png">
    <!-- Format -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="../format/app.css">
    <link rel="stylesheet" href="../format/bootstrap.min.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    <script src="../format/app.js"></script>

  </head>

  <body style="text-align: center;">  
    <div class="container" id="main">  
        <div class="row">  
            <h1 class="col-md-12 text-center">  
                Path-adaptive Spatio-Temporal State Space Model for Event-based Recognition with Arbitrary Duration<br />   
            </h1>  
        </div>  
        
        <div class="row">  
            <div class="col-md-12 text-center">  
                <ul class="list-inline">  
                    <li style="vertical-align: top;">  
                        <img src="./images/jiazhou.jpg" height="80px" style="object-fit: cover;"><br>  
                        <a href="https://jiazhou-garland.github.io/">  
                         Jiazhou Zhou  
                        </a>  
                        <br /> AI Thrust, HKUST(GZ)  
                        <br /> International Digital   
                        <br /> Economy Academy (IDEA)  
                    </li>  

                    <li style="vertical-align: top;">  
                        <img src="./images/khao.jpg" height="80px" style="object-fit: cover;"><br>  
                        <a href="https://scholar.google.com/citations?user=IwvcylUAAAAJ&hl=zh-CN">  
                            Kanghao Chen  
                        </a>  
                        <br /> AI Thrust, HKUST(GZ)  
                    </li>  

                    <li style="vertical-align: top;">  
                        <img src="./images/leizhang.jpg" height="80px" style="object-fit: cover;"><br>  
                        <a href="https://www.leizhang.org/">  
                           Lei Zhang  
                        </a>  
                        <br /> International Digital   
                        <br /> Economy Academy (IDEA)  
                    </li>  

                    <li style="vertical-align: top;">  
                        <img src="./images/linwang.jpg" height="80px" style="object-fit: cover;"><br>  
                        <a href="https://addisonwang2013.github.io/vlislab/linwang.html">  
                            Addison Lin Wang  
                        </a>  
                        <br/> School of Electrical and Electronie Engineering,
                        <br/> Nanyang Technological Universily  

                        
                    </li>  
                </ul>  
            </div>  
        </div>  


        <!-- ##### Elements #####-->
        <div class="row">
                <div class="col-md-8 col-md-offset-2 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
			    <a href="http://arxiv.org/abs/2409.16953">
                            <img src="./images/arxiv.png" height="100px"><br>
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
			    
                       <!-- <li>

                            <img src="./images/youtube_icon.jpg" height="100px"><br>
                                <h4><strong>Video</strong></h4>
                            </a>
                        </li>-->

			    
                        <li>
                            <a href="https://github.com/jiazhou-garland/PASS">
                            <img src="./images/github_icon.jpg" height="100px"><br>
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li>

                        <li>
                            
                            <img src="./images/huggingface.jpg" height="100px"><br>
                                <h4><strong>Huggingface</strong></h4>
                            </a>
                        </li>
 

                        <!-- <li>
                            <a href="https://github.com/jiazhou-garland/ELIP/blob/master/Appendix.pdf">
                            <img src="./images/slide_icon.jpg" height="100px"><br>
                                <h4><strong>Supp</strong></h4>
                            </a>
                        </li>  -->       

                        <!-- <li>
                            <a href="https://vlislab22.github.io/vlislab/">
                            <img src="./images/lab_logo.png" height="100px"><br>
                                <h4><strong>Vlislab</strong></h4>
                            </a>
                        </li>                        -->
                      
                    </ul>
                </div>
        </div>

        <div class="row">     
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Compared to previous event-based recognition methods limited to a narrow distribution of event length and poor temporal frequency generalization, 
                    our method, PASS, advances spatial-temporal event modeling across a broader distribution of event length ranging from 1 to 10^9 and demonstrates superior temporal frequency generalization.
                </h3>
                <img src="./images/cTesearFig.pdf" class="img-responsive" alt="vis_res"  class="center" >
              </div>
        </div>


        <!-- ##### Abstract #####-->
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                    Event cameras are bio-inspired sensors that capture intensity changes asynchronously with distinct advantages, such as high temporal resolution. Existing methods for event-based object/action recognition predominantly sample and convert event representation at every fixed temporal interval (or frequency). However, they are constrained to processing a limited number of event lengths and show poor frequency generalization, thus not fully leveraging the event's high temporal resolution. In this paper, we 
                    present our PASS framework, exhibiting superior capacity for spatiotemporal event modeling towards a larger number of event lengths and generalization across varying inference temporal frequencies.
                    Our key insight is to learn adaptively encoded event features via the state space models (SSMs), whose linear complexity and generalization on input frequency make them ideal for processing high temporal resolution events. 
                    Specifically, we propose a Path-selective Event Aggregation and Scan (PEAS) module to encode events into features with fixed dimensions by adaptively scanning and selecting aggregated event presentation. On top of it, we introduce a novel Multi-faceted Selection Guiding (MSG) loss to minimize the randomness and redundancy of the encoded features during the PEAS selection process. Our method outperforms prior methods on five public datasets and shows strong generalization across varying inference frequencies with less accuracy drop ( ours -8.62% v.s. -20.69% for the baseline). 
                    Moreover, our model exhibits strong long spatiotemporal modeling for a broader distribution of event length (1-$10^9$), precise temporal perception, and effective generalization for real-world scenarios.
                </p>
            </div>
        </div>

 

        <!-- ##### Results #####-->

     <div class="row">     
        <div class="col-md-8 col-md-offset-2">
            <h3>
                Overall framework of our PAST-SSM
            </h3>
            <img src="./images/cFramework.pdf" class="img-responsive" alt="vis_res"  class="center" >
      	</div>
    </div>
<!-- ####      <div class="col-md-8 col-md-offset-2">
          <h3>
              Comparison on octree representations
          </h3>
          <p class="text-justify">
            DOT shows the more compact structure of DOT, 
            resulting in fewer ray intersections, explaining our significant rendering speed boost.

          </p>
		  <img src="./image/dot_cp.png" class="img-responsive" alt="vis_res" class="center"><br>
    </div>   
    <div class="col-md-8 col-md-offset-2">
        <h3>
            Comparison on visual quality and memory consumption
        </h3>
        <p class="text-justify">
            DOT provides more details in complex regions, such as sharper reflections on windows and more evident edges on fences. 

        </p>
        <img src="./image/dot_cp2.png" class="img-responsive" alt="vis_res" class="center"><br>
    </div>     
    </div>


		      
    	<div class="row">      
     <div class="col-md-8 col-md-offset-2">
          <h3>
              Demo 
          </h3>   
    </div>   
      
    <div class="col-md-8 col-md-offset-2">

            <video width="800"  controls >
                <source src="./video/dot.mp4" type="video/mp4">
              Your browser does not support HTML video.
            </video>   
    </div>          
      </div>  ####-->
   <!-- ##### BibTex #####-->
        <hr>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    BibTeX
                </h3>
 
                <div class="row align-items-center">
                    <div class="col py-3">
                        <pre class="border">             
@article{zhou2024pastssm,
  title={Path-adaptive Spatio-Temporal State Space Model for Event-based Recognition with Arbitrary Duration},
  author={Zhou, Jiazhou and Kanghao, Chen and Lei, Zhang and Wang, Lin},
  journal={arXiv preprint arXiv:2308.03135},
  year={2024}
}
</pre>
                    </div>
                </div>
              
    
          </div>
          
        </div>
    </div>
</body>
</html>
